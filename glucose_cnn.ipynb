{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/supertime1/glucose/blob/main/glucose_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PKtRLCMgCbpd"
      },
      "source": [
        "## 1. Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xkgT3Hv67N8T",
        "outputId": "8512a7c5-b85f-4a8a-8195-8a85041bdffd"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # change directory to load Profusa tensorflow modules\n",
        "%cd drive/My\\ Drive/Glucose_Algorithm/glucose\n",
        "!git clone https://supertime1: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@github.com/supertime1/glucose.git\n",
        "!git pull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Apx8n1U05_vu",
        "outputId": "fa4f1e5a-7e03-4272-c9e5-1d560542ac60"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "\n",
        "!pip install tensorflow_lattice\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Input, Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "\n",
        "print(tf.__version__)\n",
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.python.client import device_lib\n",
        "device_lib.list_local_devices()\n",
        "from typing import Tuple\n",
        "from pathlib import Path\n",
        "import glob\n",
        "\n",
        "\n",
        "from TFDataPreprocessor import TFDataPreprocessor\n",
        "from TFTrainer import TFTrainer\n",
        "%load_ext tensorboard\n",
        "\n",
        "mirrored_strategy = tf.distribute.MirroredStrategy()\n",
        "# cluster_resolver = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "# tf.config.experimental_connect_to_cluster(cluster_resolver)\n",
        "# tf.tpu.experimental.initialize_tpu_system(cluster_resolver)\n",
        "# tpu_strategy = tf.distribute.TPUStrategy(cluster_resolver)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rf7vja4bj-BA"
      },
      "outputs": [],
      "source": [
        "# setup global variables\n",
        "_DATA_PATH = '/content/drive/MyDrive/Glucose_Data/rnn/128_timesteps/'\n",
        "# _DATA_PATH = os.path.join(Path(os.getcwd()).parent, 'glucose_algorithm', 'notebooks')\n",
        "_MODEL_OUTPUT_PATH = '/content/drive/MyDrive/Glucose_Algorithm/'\n",
        "# _MODEL_OUTPUT_PATH = os.getcwd\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Train and Save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "_subfolder_path_lst = glob.glob(os.path.join(_DATA_PATH, '*fold'))\n",
        "\n",
        "for subfolder_path in _subfolder_path_lst:\n",
        "    tf_data_preprocessor = TFDataPreprocessor(subfolder_path)\n",
        "    train_data, test_data, train_label, test_label = tf_data_preprocessor.process(augument=False)\n",
        "    assert tf_data_preprocessor.fold_idx == os.path.split(subfolder_path)[4:]\n",
        "    \n",
        "    tf_trainer = TFTrainer(train_data, train_label, _MODEL_OUTPUT_PATH, tf_data_preprocessor.fold_idx)\n",
        "    tf_trainer.train()\n",
        "    tf_trainer.export_logs()\n",
        "    tf_trainer.save_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYWBM1aoolM_"
      },
      "source": [
        "## Make prediction on test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P23Mh-i_g05r"
      },
      "outputs": [],
      "source": [
        "def prediction_with_customized_training(base_model, test_data_slice, test_label_slice):\n",
        "    \n",
        "    base_model.trainable = False\n",
        "    inputs = Input(shape=(test_data.shape[1:]))\n",
        "    x = base_model(inputs, training=False)\n",
        "    x = Dense(256, activation='relu', kernel_initializer = glorot_uniform(seed=0))(x)\n",
        "    outputs = Dense(45, activation='relu', kernel_initializer = glorot_uniform(seed=0))(x)\n",
        "    model = Model(inputs, outputs)\n",
        "    \n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), \n",
        "                  loss=tf.keras.losses.MeanSquaredError(), \n",
        "                  metrics=['mae'])\n",
        "    model.fit(test_data_slice, test_label_slice, epochs=50)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4tsfO0HN_YuO"
      },
      "outputs": [],
      "source": [
        "base_model = model.encoder\n",
        "\n",
        "for key, val in test_data_dict.items():\n",
        "    # get one experiment data\n",
        "    test_data = test_data_dict[key]\n",
        "    test_label = test_label_dict[key]\n",
        "    \n",
        "    predicted_glucose = []\n",
        "    assert len(test_data) == len(test_label), 'need to have a paried test data and its label!'\n",
        "    # get test data and label for fine tuning model\n",
        "    test_data_slice_for_training = test_data\n",
        "    test_label_slice_for_training = test_label\n",
        "\n",
        "    # test_data_slice_for_training = np.reshape(test_data_slice_for_training, (1, test_data_slice_for_training.shape[0], test_data_slice_for_training.shape[1]))\n",
        "    # test_label_slice_for_training = np.reshape(test_label_slice_for_training, (1, test_label_slice_for_training.shape[0]))\n",
        "    \n",
        "    custom_model = prediction_with_customized_training(base_model, test_data_slice_for_training, \n",
        "                                                            test_label_slice_for_training)\n",
        "    predicted_glucose.append(model.predict(test_data))\n",
        "    #TODO: need to calibrate predicted_glucose_signal with its blood glucose label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoGytrcD1w24",
        "outputId": "9de0e114-d2b2-4925-b83d-e6fb952a2304"
      },
      "outputs": [],
      "source": [
        "!pip install lmfit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V5bcbgE71tCn"
      },
      "outputs": [],
      "source": [
        "import lmfit\n",
        "import logging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_zJ4xLkjzcu"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.load_model(os.path.join(_GOOGLE_DRIVE_PATH, _TRAINED_MODEL_NAME))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "znfbpOGfXSzi"
      },
      "outputs": [],
      "source": [
        "def r_squared(yhat, y):\n",
        "    # R squared explaining how much of the variance in y can be explained by yhat\n",
        "    ybar = np.mean(y)\n",
        "    ssres = np.sum((y - yhat)**2)  # sum of variance explained by yhat\n",
        "    sstot = np.sum((y - ybar)**2)  # sum of total variance\n",
        "    return 1-(ssres/sstot)\n",
        "\n",
        "def parkes_type_1(act, pred, title_peg=\"\", lbls=[], display_stats=True, group_key_list=['Experiment'], ax=None):\n",
        "    \"\"\"compares the actual glucose (act) vs predicted glucose (pred) on a type-1 Parkes error grid\n",
        "    a tittle nd a list with reader nmes cna be pssed to be used for title and legends. For multi eperiment plot, \n",
        "    act and pred are matrices with the values for each experiment in each line, padded with Nans so all rows are the same length.\n",
        "    the lbls list shouldhave the name of eachexperiment in the ame order as the rows in the input matrices\"\"\"\n",
        "    maxglu = 450\n",
        "    n_too_high = len([v for v in pred.flatten() if v >= maxglu])\n",
        "    n_too_low = len([v for v in pred.flatten() if v <= 0])\n",
        "    if n_too_high + n_too_low > 0:\n",
        "        logging.warn(\n",
        "            f'Values outside of Parkes range: {n_too_high} values >= {maxglu} and {n_too_low} values <= 0 ')\n",
        "    if len(act.shape) == 1:\n",
        "        # This will trow an error if there is mimatch\n",
        "        [nact, npred] = [act[np.isfinite(act)], pred[np.isfinite(act)]]\n",
        "    else:\n",
        "        aux1 = act.flatten()\n",
        "        aux2 = pred.flatten()\n",
        "        [nact, npred] = [aux1[np.isfinite(aux1)], aux2[np.isfinite(aux2)]]\n",
        "    a, b, c, d, e = 0, 0, 0, 0, 0\n",
        "    X = [[0, 0, 35], [0, 35, 50], [0, 25, 50, 80, 125], [0, 30, 50, 70, 260],\n",
        "         [0, 30, 140, 280, 430], [50, 50, 170, 385, 550], [120, 120, 260, 550], [250, 250, 550], [250, 550, 550]]\n",
        "    Y = [[150, 550, 550], [150, 155, 550], [100, 100, 125, 215, 550], [60, 60, 80, 110, 550],\n",
        "         [50, 50, 170, 380, 550],\n",
        "         [0, 30, 145, 300, 450], [0, 30, 130, 250], [0, 40, 150], [0, 0, 150]]\n",
        "    # areas = 'EDCBABCD'\n",
        "    if ax is None:\n",
        "        f = plt.figure(figsize=(8,6))\n",
        "        ax = plt.subplot(1, 1, 1)\n",
        "    #plt.text(maxglu-int(0.1*maxglu), int(maxglu*300/550), 'B', fontsize=14)\n",
        "    ax.text(maxglu-int(0.1*maxglu), int(maxglu*300/550), 'B', fontsize=14)\n",
        "    #plt.text(maxglu-int(0.1*maxglu), int(maxglu*170/550), 'C', fontsize=14)\n",
        "    ax.text(maxglu-int(0.1*maxglu), int(maxglu*170/550), 'C', fontsize=14)\n",
        "    #plt.text(maxglu-int(0.1*maxglu), int(maxglu*50/550), 'D', fontsize=14)\n",
        "    ax.text(maxglu-int(0.1*maxglu), int(maxglu*50/550), 'D', fontsize=14)\n",
        "    y1 = np.zeros(550)\n",
        "    y2 = np.zeros(550)\n",
        "    xvec = np.arange(550)\n",
        "    # for every pair, construct two vectors with the lines\n",
        "    c = ['red', 'lightcoral', 'sandybrown', 'yellow', 'greenyellow', 'yellow', 'sandybrown', 'lightcoral']\n",
        "    counts = np.zeros(len(c))\n",
        "    for nump, xtp in enumerate(X[:-1]):\n",
        "        xtp2 = X[nump + 1]\n",
        "        y1 = np.zeros(550)\n",
        "        y2 = np.zeros(550)\n",
        "        for i, el in enumerate(xtp[:-1]):\n",
        "            y1[el:xtp[i + 1]] = np.linspace(start=Y[nump][i], stop=Y[nump][i + 1], num=xtp[i + 1] - el)\n",
        "        y1[xtp[i + 1]:] = 550\n",
        "        if xtp[0] > 0:\n",
        "            y1[:xtp[0] - 1] = None\n",
        "        ax.plot(xvec, y1, 'k-', linewidth=0.7)\n",
        "        for i2, el2 in enumerate(xtp2[:-1]):\n",
        "            y2[el2:xtp2[i2 + 1]] = np.linspace(start=Y[nump + 1][i2], stop=Y[nump + 1][i2 + 1],\n",
        "                                               num=xtp2[i2 + 1] - el2)\n",
        "            ax.fill_between(xvec, y1, y2, color=c[nump])\n",
        "            # counting % in each area\n",
        "        for i in np.arange(len(npred)):\n",
        "            # find position in xvect, y1 and y2\n",
        "            pos = np.argmin(np.abs(xvec-nact[i]))\n",
        "            if nump == 0:\n",
        "                if y1[pos] == maxglu and y2[pos] < maxglu and y2[pos] > 0 and npred[i] >= y2[pos]:\n",
        "                    counts[nump] += 1\n",
        "            if nump > 0 and nump < 4:\n",
        "                # y1[pos]<550 and y2[pos]>0 and\n",
        "                if y2[pos] > 0 and (npred[i] >= y2[pos]) and (npred[i] <= y1[pos]):\n",
        "                    counts[nump] += 1\n",
        "            if nump == 4:\n",
        "                # y1[pos]<550 and y2[pos]>0 and\n",
        "                if (npred[i] >= y2[pos]) and (npred[i] <= y1[pos]):\n",
        "                    counts[nump] += 1\n",
        "            if nump > 4 and nump < 7:\n",
        "                # y1[pos]<550 and y2[pos]>0 and\n",
        "                if y1[pos] > 0 and (npred[i] >= y2[pos]) and (npred[i] <= y1[pos]):\n",
        "                    counts[nump] += 1\n",
        "            if nump == 7:\n",
        "                if y1[pos] > 0 and npred[i] <= y1[pos]:\n",
        "                    counts[nump] += 1\n",
        "    counts = 100*counts/np.sum(counts)\n",
        "    e = round(counts[0], 1)\n",
        "    d = round(counts[1]+counts[-1], 1)\n",
        "    c = round(counts[2]+counts[-2], 1)\n",
        "    b = round(counts[3]+counts[-3], 1)\n",
        "    a = 100 - b - c - d - e  # counts[4]\n",
        "    ax.text(int(maxglu*5/550), int(maxglu*510/550), 'E', fontsize=14)\n",
        "    if e > 0:\n",
        "        ax.text(int(maxglu*4/550), int(maxglu*480/550), '%.1f%%' %\n",
        "                 e, fontsize=14, color=[0.2, 0.2, 0.2])\n",
        "    ax.text(int(maxglu*100/550), int(maxglu*510/550), 'D', fontsize=14)\n",
        "    if d > 0:\n",
        "        ax.text(int(maxglu*90/550), int(maxglu*480/550),\n",
        "                 '%.1f%%' % d, fontsize=14)\n",
        "    ax.text(int(maxglu*170/550), int(maxglu*510/550), 'C', fontsize=14)\n",
        "    if c > 0:\n",
        "        ax.text(int(maxglu*160/550), int(maxglu*480/550),\n",
        "                 '%.1f%%' % c, fontsize=14)\n",
        "    ax.text(int(maxglu*300/550), int(maxglu*510/550), 'B', fontsize=14)\n",
        "    if b > 0:\n",
        "        ax.text(int(maxglu*289/550), int(maxglu*480/550),\n",
        "                 '%.1f%%' % b, fontsize=14)\n",
        "    ax.text(int(maxglu*490/550), int(maxglu*510/550), 'A', fontsize=14)\n",
        "    if a > 0:\n",
        "        ax.text(int(maxglu*470/550), int(maxglu*480/550),\n",
        "                 '%.1f%%' % a, fontsize=14)\n",
        "    ax.set_xlim([0, maxglu])\n",
        "    ax.set_ylim([0, maxglu])\n",
        "    if len(act.shape) > 1:\n",
        "        if len(lbls) > 0:\n",
        "            label_exp = lbls\n",
        "        else:\n",
        "            label_exp = ['Exp '+str(i) for i in range(1, 1+act.shape[0])]\n",
        "        for i in list(range(act.shape[0])):\n",
        "            aux1 = act[i, :]\n",
        "            aux2 = pred[i, :]\n",
        "            good_x, good_y, bad_x, bad_y = [], [], [], []\n",
        "            for mi in range(len(aux1)):\n",
        "                m1, m2 = aux1[mi], aux2[mi]\n",
        "                if m1 > maxglu or m1 < 0 or m2 > maxglu or m2 < 0:\n",
        "                    bad_x.append(max(min(m1, maxglu-1), 1))\n",
        "                    bad_y.append(max(min(m2, maxglu-1), 1))\n",
        "                else:\n",
        "                    good_x.append(m1)\n",
        "                    good_y.append(m2)\n",
        "\n",
        "            marker_color = cm.get_cmap('gist_rainbow')(i/act.shape[0])\n",
        "            ax.plot(good_x, good_y, 'o', markersize=7,\n",
        "                     markerfacecolor=marker_color,\n",
        "                     markeredgewidth=0.6, markeredgecolor='k',\n",
        "                     alpha=0.8, label=label_exp[i])\n",
        "            ax.plot(bad_x, bad_y, 'X', markersize=7,\n",
        "                     markerfacecolor=marker_color,\n",
        "                     markeredgewidth=0.6, markeredgecolor='k',\n",
        "                     alpha=0.8)\n",
        "\n",
        "        ax.legend(title=\" \".join(group_key_list),\n",
        "                   bbox_to_anchor=(1.03, 1), loc='upper left', ncol=2)\n",
        "    else:\n",
        "        ax.plot(nact, npred, 'ko', alpha=0.9)\n",
        "    ax.set_xlabel('Measured BG (mg/dL)', fontsize=15)\n",
        "    ax.set_ylabel('Estimated BG (mg/dL)', fontsize=15)\n",
        "    fontsize = 19\n",
        "    title = \"\"\n",
        "    if display_stats or len(title_peg)==0:\n",
        "        title = ' MARD: {0:.1f}%, $R^2$ = {1:.2f}'.format(\n",
        "            100*np.nanmean(np.abs(np.array(npred)-np.array(nact))/np.array(nact)), r_squared(npred, nact))\n",
        "    title = title_peg + title\n",
        "    if n_too_high + n_too_low > 0:\n",
        "        title = f'{n_too_high + n_too_low} values not plotted; ' + title\n",
        "        fontsize = 12\n",
        "    ax.set_title(title, fontsize=fontsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpDEB43ZiPxs"
      },
      "outputs": [],
      "source": [
        "def one_point_calibration(pred: np.array, real: np.array) -> np.array:\n",
        "    \"\"\" apply one point calibration, which returns a series of predicted values after applying a scaler, which is calculated by the first point \"\"\"\n",
        "    scaler = real[0] / pred[0]\n",
        "    return pred * scaler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfptNUfk1e4b"
      },
      "outputs": [],
      "source": [
        "def flin(x, a, b):\n",
        "    \"\"\" linear function \"\"\"\n",
        "    return (a * x + b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "olQzCwWtzpkv"
      },
      "outputs": [],
      "source": [
        "def two_point_calibration(pred: np.array, real: np.array) -> np.array:\n",
        "    \"\"\" apply two point calibration, which returns a series of predicted values after applying linear regression coefficiency \"\"\"\n",
        "    min_idx, max_idx = np.argmin(real), np.argmax(real)\n",
        "    lin_model = lmfit.Model(flin)\n",
        "    lin_model.set_param_hint('a', value=0)\n",
        "    lin_model.set_param_hint('b', value=0)\n",
        "    init_pars_lin = lin_model.make_params() \n",
        "    lin_results = lin_model.fit(x=pred[[min_idx, max_idx]], params=init_pars_lin, data=real[[min_idx, max_idx]])\n",
        "    pars_lin = lin_results.params\n",
        "    return pars_lin['a'] * pred + pars_lin['b']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l1E5k6QXf6Ne"
      },
      "outputs": [],
      "source": [
        "# make prediction by each experiment and append to accumlated results\n",
        "def make_prediction_with_calibration(test_data_dict: dict, test_label_dict: dict, calibration_method: str) -> Tuple[np.array, np.array]:\n",
        "    all_pred = []\n",
        "    all_real = []\n",
        "    n = 0\n",
        "    for key, val in test_data_dict.items():\n",
        "        n += 1\n",
        "        if len(val) == 0:\n",
        "            continue\n",
        "        per_exp_test_label = test_label_dict[key]\n",
        "        test_label = np.mean(per_exp_test_label, axis=1)\n",
        "        # print(f'test_label shape: {test_label.shape}')\n",
        "        per_exp_test_pred = model.predict(val)\n",
        "        # print(f'pred_label shape: {per_exp_test_pred.shape}')\n",
        "\n",
        "        if calibration_method == 'one':\n",
        "            # apply 1-point calibration\n",
        "            calibrated_pred = one_point_calibration(per_exp_test_pred, test_label)\n",
        "        if calibration_method == 'two':\n",
        "            # apply 2-point calibration\n",
        "            calibrated_pred = two_point_calibration(per_exp_test_pred, test_label)\n",
        "        \n",
        "        if n % 10 == 0:\n",
        "            plt.plot(per_exp_test_pred, label='raw predict')\n",
        "            plt.plot(test_label, label='test label')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "            plt.plot(calibrated_pred, label='calibrated predict')\n",
        "            plt.plot(test_label, label='test label')\n",
        "            plt.show()\n",
        "            plt.close()\n",
        "\n",
        "        all_pred.append(calibrated_pred)\n",
        "        all_real.append(test_label)\n",
        "\n",
        "    return np.array([i for sublist in all_pred for i in sublist]), np.array([i for sublist in all_real for i in sublist])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npBUv_uza5r9"
      },
      "outputs": [],
      "source": [
        "test_data = np.array([j for i in test_data_dict.keys() for j in test_data_dict[i]])\n",
        "test_label = np.array([j for i in test_label_dict.keys() for j in test_label_dict[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YhAlpI_44_Tt"
      },
      "outputs": [],
      "source": [
        "all_pred, all_real = make_prediction_with_calibration(test_data, test_label, 'two')\n",
        "parkes_type_1(all_real, all_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-42v1XenC2rA",
        "outputId": "af87084c-9259-451b-a645-aca744b53140"
      },
      "outputs": [],
      "source": [
        "# drive.flush_and_unmount()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyNmS60ez8lSoSSB3/486amA",
      "collapsed_sections": [],
      "include_colab_link": true,
      "machine_shape": "hm",
      "name": "glucose_cnn.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "fec8ce8b7c675468ad9fbbdf6cb7aad3455ec94c16656ad97df2fb62c7ddd62e"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
